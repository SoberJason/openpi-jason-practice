import h5py
import torch
import numpy as np
from pathlib import Path
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
import tqdm
import shutil

# ================= é…ç½®åŒºåŸŸ =================
# è¾“å…¥ï¼šç”Ÿæˆçš„åŒ…å« RGB çš„ .h5 æ–‡ä»¶
INPUT_H5_PATH = "data/maniskill/PickCube-v1/motionplanning/trajectory.rgb.pd_ee_delta_pose.physx_cpu.h5" 

# è¾“å‡ºï¼šè½¬æ¢åçš„ LeRobot æ•°æ®é›†å­˜æ”¾ä½ç½®
REPO_ID = "jason/pi05-maniskill-pickcube"
LOCAL_DIR = "data/lerobot_datasets/pi0_maniskill_pickcube"
FPS = 20 # ManiSkill é»˜è®¤æ§åˆ¶é¢‘ç‡

# ä»»åŠ¡æè¿° (ManiSkill PickCube-v1 çš„ä»»åŠ¡å°±æ˜¯æŠ“å–çº¢è‰²æ–¹å—)
TASK_DESCRIPTION = "pick up the red cube"
# ===========================================

def convert_dataset():
    input_path = Path(INPUT_H5_PATH)
    if not input_path.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_path}")
        return

    # å¦‚æœè¾“å‡ºç›®å½•å­˜åœ¨ï¼Œå…ˆæ¸…ç†æ‰ï¼Œé˜²æ­¢è¿½åŠ å¯¼è‡´æ•°æ®é‡å¤æˆ–é”™è¯¯
    if Path(LOCAL_DIR).exists():
        print(f"âš ï¸  è­¦å‘Š: è¾“å‡ºç›®å½• {LOCAL_DIR} å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ é™¤ä»¥é‡æ–°ç”Ÿæˆ...")
        shutil.rmtree(LOCAL_DIR)

    print(f"ğŸš€ æ­£åœ¨è¯»å–åŸå§‹æ•°æ®: {input_path}")
    
    # 1. åˆå§‹åŒ– LeRobot æ•°æ®é›†
    # ä¸ä»…å­˜å‚¨å›¾åƒå’ŒåŠ¨ä½œï¼Œè¿˜å­˜å‚¨æœºæ¢°è‡‚çš„çŠ¶æ€ (qpos + qvel)
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åœ¨ features é‡Œä¸å†™ "task"ï¼Œ
    # å› ä¸º LeRobot ä¼šè‡ªåŠ¨åŠ ä¸Šå®ƒã€‚å¦‚æœæˆ‘ä»¬è‡ªå·±å†™å®¹æ˜“å‚æ•°ä¸å¯¹ã€‚
    dataset = LeRobotDataset.create(
        repo_id=REPO_ID,
        fps=FPS,
        root=LOCAL_DIR,
        robot_type="panda",
        # æ˜¾å¼å®šä¹‰ç‰¹å¾ï¼Œç¡®ä¿ OpenPI èƒ½æ­£ç¡®è¯†åˆ«
        features={
            "observation.images.base_camera": {
                "dtype": "image", 
                "shape": (128, 128, 3), # æ ¹æ®æ‰“å°çš„H5æ–‡ä»¶ç»“æ„ï¼š128x128
                "names": ["height", "width", "channel"]
            },
            "observation.state": {
                "dtype": "float32", 
                "shape": (18,),
                "names": ["state_dim"]
            },
            "action": {
                "dtype": "float32", 
                "shape": (7,), # æ ¹æ®æ‰“å°çš„H5æ–‡ä»¶ç»“æ„ï¼š7 dim
                "names": ["action_dim"]
            },
        },
        image_writer_threads=4,
    )

    # 2. è¯»å– H5 æ–‡ä»¶å¹¶è½¬æ¢
    with h5py.File(input_path, "r") as f:
        traj_keys = sorted([k for k in f.keys() if k.startswith("traj_")])
        print(f"ğŸ“Š å‘ç° {len(traj_keys)} æ¡è½¨è¿¹ï¼Œå¼€å§‹è½¬æ¢...")
        
        for key in tqdm.tqdm(traj_keys, desc="è½¬æ¢è¿›åº¦"):
            traj = f[key]
            
            # --- æå–æ•°æ® (åŸºäºæ‰“å°çš„H5æ–‡ä»¶ç»“æ„) ---
            
            # 1. å›¾åƒ (uint8 -> Tensor)
            # è·¯å¾„: /obs/sensor_data/base_camera/rgb
            img_data = traj["obs"]["sensor_data"]["base_camera"]["rgb"][:]

            # 2. çŠ¶æ€ (qpos + qvel)
            # è·¯å¾„: /obs/agent/qpos, /obs/agent/qvel
            qpos = traj["obs"]["agent"]["qpos"][:]
            qvel = traj["obs"]["agent"]["qvel"][:]
            # æ‹¼æ¥æˆä¸€ä¸ª 18ç»´å‘é‡
            state_data = np.concatenate([qpos, qvel], axis=-1)

            # 3. åŠ¨ä½œ
            # è·¯å¾„: /actions
            action_data = traj["actions"][:]
            
            # --- é•¿åº¦å¯¹é½ ---
            # ManiSkill: Obs (75) = Initial + 74 steps,  Action (74)
            # LeRobot:   è¦æ±‚ä¸€ä¸€å¯¹åº” (Obs[i] -> Action[i])
            # åšæ³•: ä¸¢å¼ƒæœ€åä¸€å¸§ Obs (å®ƒæ˜¯æ‰§è¡Œå®Œæœ€åä¸€ä¸ªåŠ¨ä½œåçš„ç»“æœï¼Œæ²¡æœ‰ä¸‹ä¸€ä¸ªåŠ¨ä½œäº†)
            n_actions = action_data.shape[0]
            
            # --- å†™å…¥ LeRobot ---
            for i in range(n_actions):
                frame_dict = {
                    "observation.images.base_camera": torch.from_numpy(img_data[i]),
                    "observation.state": torch.from_numpy(state_data[i]).float(),
                    "action": torch.from_numpy(action_data[i]).float(),
                    # å…³é”®ä¿®æ”¹ï¼šè™½ç„¶ä¸Šé¢ features æ²¡å†™ï¼Œä½†æ ¡éªŒå™¨è¦è¿™ä¸ªï¼Œæˆ‘ä»¬å¿…é¡»ç»™ï¼
                    "task": TASK_DESCRIPTION
                }
                dataset.add_frame(frame_dict)
            
            # æ ‡è®°ä¸€æ¡è½¨è¿¹ç»“æŸ
            dataset.save_episode()
     
    # 3. æ•´åˆå¹¶ä¿å­˜ç»Ÿè®¡ä¿¡æ¯       
    print("ğŸ’¾ æ­£åœ¨æ•´åˆæ•°æ®é›†...")
    dataset.consolidate()
    print(f"\nâœ… è½¬æ¢æˆåŠŸï¼æ•°æ®é›†ä½ç½®: {LOCAL_DIR}")

if __name__ == "__main__":
    convert_dataset()